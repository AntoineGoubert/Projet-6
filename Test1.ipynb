{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1st CNN predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model = tensorflow.keras.Sequential([wholemodel_cnn,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)\n",
    "plot_prediction_images(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2nd CNN predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model2 = tensorflow.keras.Sequential([wholemodel_cnn2,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions2 = probability_model2.predict(test_images)\n",
    "plot_prediction_images(predictions2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG16 predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model = tensorflow.keras.Sequential([wholemodel,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions_vgg = probability_model.predict(test_images)\n",
    "plot_prediction_images(predictions_vgg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test avec images de base"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_image,test_image,train_label, test_label = train_test_split(data_original.loc[:,['Image','Grayscale']],data.loc[:,['Race','RaceId']],stratify=data['RaceId'],test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_counts = pd.DataFrame({\n",
    "    'data': np.array(['train'] * num_classes + ['test'] * num_classes),\n",
    "    'class': np.tile(np.arange(num_classes), 2),\n",
    "    'prop': np.hstack([np.bincount(train_label['RaceId']) / train_label.shape[0],\n",
    "                         np.bincount(test_label['RaceId']) / test_label.shape[0]])\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(x='class', y='prop', hue='data', data=y_counts, ax=ax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "k=0\n",
    "for i in train_image.index[:25]:\n",
    "    plt.subplot(5,5,k+1)\n",
    "    k+=1\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_image['Image'][i])\n",
    "    plt.xlabel(train_label['Race'][i])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We normalize the data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images = train_image['Image']\n",
    "test_images = test_image['Image']\n",
    "\n",
    "train_labels=train_label['RaceId']\n",
    "test_labels=test_label['RaceId']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(data['Grayscale'][0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The scale of grey is now from 0 to 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###**Creation of a validation set**\n",
    "\n",
    "We further split the train set into a train and validation set. The validation set will be 20% from the original train set, therefore the split will be train/validation of 0.8/0.2.\n",
    "\n",
    "The actual training set will be divided into two groups:\n",
    "* the training set\n",
    "* the validation set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=2020)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_id=train_images.index\n",
    "valid_id=valid_images.index\n",
    "test_id=test_images.index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "partition = {'train' : [str(i) for i in train_id], 'validation' : [str(i) for i in valid_id]}\n",
    "\n",
    "labels={}\n",
    "for i in train_id:\n",
    "    labels[str(i)]=train_labels[i]\n",
    "for i in valid_id:\n",
    "    labels[str(i)]=valid_labels[i]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We define a class used not to overflow our GPU."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs=200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=batch_size, dim=input_shape, n_classes=num_classes, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = data['Image'][int(ID)]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images=np.asarray([i.astype(np.float32) for i in train_images])\n",
    "\n",
    "valid_images=np.asarray([i.astype(np.float32) for i in valid_images])\n",
    "\n",
    "test_images=np.asarray([i.astype(np.float32) for i in test_images])\n",
    "\n",
    "#Generators\n",
    "\n",
    "training_generator = DataGenerator(partition['train'], labels)\n",
    "validation_generator = DataGenerator(partition['validation'], labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=10,  restore_best_weights=True)\n",
    "\n",
    "\n",
    "time0=time.time()\n",
    "wholemodel_cnn2 = Sequential()\n",
    "wholemodel_cnn2.add(Rescaling(1./255, input_shape=input_shape))\n",
    "wholemodel_cnn2.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "wholemodel_cnn2.add(LayerNormalization())\n",
    "wholemodel_cnn2.add(MaxPooling2D(pool_size=3))\n",
    "wholemodel_cnn2.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "wholemodel_cnn2.add(MaxPooling2D(pool_size=2))\n",
    "wholemodel_cnn2.add(Dropout(0.1))\n",
    "wholemodel_cnn2.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "wholemodel_cnn2.add(MaxPooling2D(pool_size=2))\n",
    "wholemodel_cnn2.add(Dropout(0.2))\n",
    "wholemodel_cnn2.add(Flatten(name='flatten'))\n",
    "wholemodel_cnn2.add(Dense(num_classes*10, activation='relu'))\n",
    "wholemodel_cnn2.add(Dense(num_classes*5, activation='relu'))\n",
    "wholemodel_cnn2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "wholemodel_cnn2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "# Run the train\n",
    "wholehistory_cnn2 = wholemodel_cnn2.fit(training_generator,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wholescore_cnn2 = wholemodel_cnn2.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', wholescore_cnn2[0])\n",
    "print('Test accuracy:', wholescore_cnn2[1])\n",
    "time1=time.time()-time0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Re-training du VGG16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(num_classes*10, activation='relu')\n",
    "dense_layer_2 = layers.Dense(num_classes*5, activation='relu')\n",
    "prediction_layer = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "\n",
    "wholemodel = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "wholemodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "wholehistory_model=wholemodel.fit(training_generator,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=validation_generator,\n",
    "                            callbacks=[es])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_set= (valid_images,valid_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wholescore_cnn = wholemodel_cnn.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', wholescore_cnn[0])\n",
    "print('Test accuracy:', wholescore_cnn[1])\n",
    "time1=time.time()-time0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wholescore_model = wholemodel.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', wholescore_model[0])\n",
    "print('Test accuracy:', wholescore_model[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Loss\n",
    "print(\"1st CNN MODEL: \")\n",
    "history_loss(wholehistory_cnn)\n",
    "print(\"2nd CNN MODEL:\")\n",
    "history_loss(wholehistory_cnn2)\n",
    "print(\"VGG16 MODEL: \")\n",
    "history_loss(wholehistory_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"1st CNN MODEL: \")\n",
    "history_accuracy(wholehistory_cnn)\n",
    "print(\"2nd CNN MODEL:\")\n",
    "history_accuracy(wholehistory_cnn2)\n",
    "print(\"VGG16 MODEL: \")\n",
    "history_accuracy(wholehistory_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "CNN = ['CNN 1','CNN 2', 'VGG16']\n",
    "Test_Accuracy = [wholescore_cnn[1],wholescore_cnn2[1],wholescore_model[1]]\n",
    "ax.bar(CNN,Test_Accuracy)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_prediction_images(prediction):\n",
    "    num_rows = 5\n",
    "    num_cols = 3\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    for i in range (num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, prediction[i], test_labels, test_images)\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, prediction[i], test_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1st CNN predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model = tensorflow.keras.Sequential([wholemodel_cnn,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)\n",
    "plot_prediction_images(predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2nd CNN predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model2 = tensorflow.keras.Sequential([wholemodel_cnn2,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions2 = probability_model2.predict(test_images)\n",
    "plot_prediction_images(predictions2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG16 predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probability_model = tensorflow.keras.Sequential([wholemodel,\n",
    "                                         tensorflow.keras.layers.Softmax()])\n",
    "predictions_vgg = probability_model.predict(test_images)\n",
    "plot_prediction_images(predictions_vgg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    img = cv.resize(data, dsize=[100, 100])\n",
    "    pred = probability_model.predict(img)\n",
    "    st.write(\"The three most likely tags are, in decreasing probability order : \", pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}